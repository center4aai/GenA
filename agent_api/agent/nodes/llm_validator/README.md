# LLM-валидатор вопросов

LLM-валидатор для оценки качества сгенерированных вопросов по критериям качества.

## Описание

Валидатор оценивает каждый сгенерированный JSON-вопрос по 5 критериям с подкритериями:

### Критерии оценки:

1. **Формулировка вопроса** (5 баллов)
   - Краткость
   - Основанность на тексте
   - Понятность
   - Не бинарность
   - Контекст

2. **Формулировка вариантов ответов / ответа** (9 баллов для тестовых, 6 для открытых)
   - Количество вариантов
   - Разнообразие
   - Правдоподобность
   - Ясность
   - Краткость
   - Отсутствие подсказок
   - Логическая связь
   - Отсутствие дублирования
   - Соответствие типу

3. **Соответствие правильных ответов** (2 балла, кроме открытых)
   - Корректность
   - Полнота/Единственность

4. **Логическая согласованность** (4 балла)
   - Логическая однозначность
   - Четкость фокусировки
   - Отсутствие противоречий
   - Логическая связанность

5. **Корректность формулировки** (2 балла)
   - Грамматическая правильность
   - Ясность и простота формулировок

### Пороговые значения:
- **Открытые вопросы (open)**: 15+ баллов из 17
- **Один выбор (one)**: 20+ баллов из 22
- **Множественный выбор (multi)**: 20+ баллов из 22

## Использование

### API Endpoint

```
POST /validate_question/
```

### Request Body

```json
{
  "question_type": "open|one|multi",
  "source_text": "Исходный текст для контекста",
  "question": {
    "task": "Текст вопроса",
    "text": "Дополнительный контекст",
    "option_1": "Вариант ответа 1",
    "option_2": "Вариант ответа 2",
    // ... другие варианты
    "outputs": "Правильный ответ"
  }
}
```

### Response

```json
{
  "status": "success",
  "result": {
    "type": "open",
    "by_block": {
      "c1_question": [1, 1, 1, 1, 1],
      "c2_outputs": [1, 1, 1, 1, 1, 1],
      "c4_logic": [1, 1, 1, 1],
      "c5_phrase": [1, 1]
    },
    "raw": {
      "c1_question": "Краткость 1\nОснованность на тексте 1\n...",
      // ... сырые ответы LLM
    },
    "total": 17,
    "max_total": 17,
    "threshold": 15,
    "passed": true
  }
}
```

## Примеры использования

### Python

```python
import requests

# Валидация открытого вопроса
response = requests.post("http://localhost:8787/validate_question/", json={
    "question_type": "open",
    "source_text": "Искусственный интеллект — это область компьютерных наук...",
    "question": {
        "task": "Что такое искусственный интеллект?",
        "outputs": "Область компьютерных наук, которая занимается созданием систем..."
    }
})

result = response.json()
if result["result"]["passed"]:
    print("✅ Вопрос прошел валидацию!")
else:
    print(f"❌ Вопрос не прошел валидацию. Балл: {result['result']['total']}")
```

### cURL

```bash
curl -X POST "http://localhost:8787/validate_question/" \
  -H "Content-Type: application/json" \
  -d '{
    "question_type": "one",
    "source_text": "Машинное обучение — это подраздел ИИ...",
    "question": {
      "task": "Что такое машинное обучение?",
      "option_1": "Область компьютерных наук",
      "option_2": "Подраздел ИИ",
      "option_3": "Технология создания роботов",
      "outputs": "2"
    }
  }'
```

## Тестирование

Запустите тестовый скрипт:

```bash
cd agent_api
python test_validator.py
```

## Архитектура

Валидатор интегрирован в существующую архитектуру agent_api:

- `validator.py` - Основной класс валидатора
- `validation_chain.py` - Интерфейс для интеграции с LangChain
- `prompts_evaluation_*/` - Папки с файлами промптов для каждого типа вопросов
- Обновлен `runnables.py` для включения валидатора
- Обновлен `handler.py` для обработки запросов валидации
- Обновлен `assistant_graph.py` для интеграции валидации в основной workflow
- Добавлен новый endpoint в `agent_api.py`

### Интеграция в основной workflow

Валидатор теперь является **обязательным шагом** в процессе генерации вопросов:

1. **Генерация вопроса** → 2. **Оценка провокативности** → 3. **Валидация качества** → 4. **Финальный результат**

Каждый сгенерированный вопрос автоматически проходит валидацию по критериям качества, и результат валидации включается в финальный ответ.

### Файлы промптов

Валидатор использует готовые файлы промптов:
- `prompts_evaluation_open/` - промпты для открытых вопросов
- `prompts_evaluation_onech/` - промпты для вопросов с одним выбором
- `prompts_evaluation_multich/` - промпты для вопросов с множественным выбором

Каждый файл содержит промпт для одного критерия оценки. Единственное исключение - для `onech/c4_logic_link` используется встроенный промпт, так как для него нет отдельного файла.

## Конфигурация

Валидатор использует те же настройки LLM, что и остальная система:

- `LLM_MODEL_NAME` - название модели
- `LLM_URL_MODEL` - URL API
- `LLM_API_KEY` - ключ API

Настройки берутся из переменных окружения или файла `.env`.

## Оптимизации производительности

Валидатор оптимизирован для максимальной скорости работы:

### LLM Оптимизации:
- **`stream=False`** - отключение стриминга для получения полного ответа сразу
- **`timeout=30`** - увеличенный timeout для больших промптов
- **`max_tokens=512`** - ограничение длины ответа для ускорения
- **`temperature=0.0`** - детерминированные ответы для стабильности

### Архитектурные оптимизации:
- Последовательная обработка критериев для стабильности
- Оптимизированные промпты с четкими инструкциями
- Эффективное извлечение бинарных векторов из ответов
- Кэширование промптов для повторного использования

### Ожидаемая производительность:
- **Открытые вопросы**: ~2-4 секунды на валидацию
- **Вопросы с выбором**: ~3-6 секунд на валидацию
- **Множественный выбор**: ~4-8 секунд на валидацию
